---
sidebar_position: 1
description: ğŸ“Œ Iris ë°ì´í„°ë¥¼ ì…ë ¥ë°›ì•„ ì˜ˆì¸¡ê°’ì„ ë°˜í™˜í•˜ëŠ” API ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
---

# 1) Model API
import CodeDescription from '@site/src/components/CodeDescription';
import BrowserWindow from '@site/src/components/BrowserWindow';
import { Chapter, Part } from '@site/src/components/Highlight';


### ëª©í‘œ

1. Iris ë°ì´í„°ë¥¼ ì…ë ¥ë°›ì•„ ì˜ˆì¸¡ê°’ì„ ë°˜í™˜í•˜ëŠ” API ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
2. ì‘ì„±í•œ API ì— ë°ì´í„°ë¥¼ ì „ë‹¬í•˜ì—¬ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

<details>
<summary>ìŠ¤í™ ëª…ì„¸ì„œ</summary>
<CodeDescription>

### ìŠ¤í™ ëª…ì„¸ì„œ

1. <Part>03. Model Registry</Part> íŒŒíŠ¸ì—ì„œ ëª¨ë¸ì„ í•™ìŠµí•œ í›„ ì €ì¥í•œ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ëª¨ë¸ì„ ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œë°›ëŠ” ìŠ¤í¬ë¦½íŠ¸ `download_model.py` ë¥¼ ì‘ì„±í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
2. `POST /predict` ë¥¼ ìˆ˜í–‰í•˜ë©´ í•™ìŠµí•œ ëª¨ë¸ì˜ inference ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” API ì˜ ëª…ì„¸ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
3. `schemas.py` ì—ì„œ Pydantic ì„ ì‚¬ìš©í•´ input schema ì™€ output schema ì˜ í´ë˜ìŠ¤ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
    - Input schema: `Class PredictIn(BaseModel)` ì„ ì´ìš©
        - Column ì´ë¦„: <Part>01. Database</Part> íŒŒíŠ¸ì—ì„œ ì‘ì„±í•œ ì´ë¦„ê³¼ ë™ì¼
    - Output schema: `Class PredictOut(BaseModel)` ì„ ì´ìš©
        - Column ì´ë¦„: `iris_class`
4. ì‘ì„±í•œ ëª…ì„¸ì„œë¥¼ FastAPI ë¥¼ ì´ìš©í•´ `app.py` ì— êµ¬í˜„í•©ë‹ˆë‹¤.
5. ì‘ì„±í•œ API ì— ë°ì´í„°ë¥¼ ì „ë‹¬í•˜ì—¬ ì˜ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

</CodeDescription>
</details>

---

<BrowserWindow url="https://github.com/mlops-for-mle/mlops-for-mle/tree/main/ch6">

í•´ë‹¹ íŒŒíŠ¸ì˜ ì „ì²´ ì½”ë“œëŠ” [mlops-for-mle/ch6/](https://github.com/mlops-for-mle/mlops-for-mle/tree/main/ch6) ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```js
ch6
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
// highlight-next-line
â”œâ”€â”€ app.py
â”œâ”€â”€ docker-compose.yaml
// highlight-next-line
â”œâ”€â”€ download_model.py
// highlight-next-line
â””â”€â”€ schemas.py
```

</BrowserWindow>

## 0. í™˜ê²½ ì„¤ì •
ì´ë²ˆ íŒŒíŠ¸ì—ì„œ ì‚¬ìš©í•  íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```bash
# terminal-command
pip install boto3==1.26.8 mlflow==1.30.0 "fastapi[all]" pandas scikit-learn
```

ë˜í•œ, ì´ë²ˆ íŒŒíŠ¸ì—ì„œë„ FastAPI ë¥¼ ì‚¬ìš©í•˜ì—¬ API ì„œë²„ë¥¼ ì‹¤í–‰í•  ì˜ˆì •ì´ë¯€ë¡œ port ê°€ ê²¹ì¹˜ëŠ” ë¬¸ì œë¥¼ ë§‰ê¸° ìœ„í•´ 05. FastAPI íŒŒíŠ¸ì—ì„œ ë„ìš´ ë„ì»¤ ì»¨í…Œì´ë„ˆë¥¼ ì¢…ë£Œí•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ í†µí•´ ì¢…ë£Œì‹œí‚µë‹ˆë‹¤.

```bash
# terminal-command
docker rm --force api-server
```

## 1. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

### 1.1 Base Setting
ë¨¼ì € í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì„ import í•©ë‹ˆë‹¤.

```python
import os
from argparse import ArgumentParser

import mlflow
```

### 1.2 Environment Variables
ë‹¤ìŒìœ¼ë¡œëŠ” ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì €ì¥ë˜ì–´ ìˆëŠ” ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê¸° ìœ„í•´ í•´ë‹¹ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì ‘ì†í•˜ê¸° ìœ„í•œ ì •ë³´ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

```python
# Set environments
os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://localhost:9000"
os.environ["MLFLOW_TRACKING_URI"] = "http://localhost:5001"
os.environ["AWS_ACCESS_KEY_ID"] = "minio"
os.environ["AWS_SECRET_ACCESS_KEY"] = "miniostorage"
```

ì´ëŠ” <Part>03. Model Registry</Part> íŒŒíŠ¸ì—ì„œ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¡œë¶€í„° ëª¨ë¸ì„ load í•  ë•Œ ì‚¬ìš©í•˜ëŠ” í™˜ê²½ ë³€ìˆ˜ì™€ ê°™ìŠµë‹ˆë‹¤.

### 1.3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ ì‘ì„±
ì´ì œ `mlflow` íŒ¨í‚¤ì§€ë¥¼ ì´ìš©í•˜ì—¬ model artifacts ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

ì—¬ê¸°ì—ì„œ model artifacts ë€, MLFlow ì— ëª¨ë¸ì´ ì €ì¥ë  ë•Œ í•¨ê»˜ ì €ì¥ëœ ë©”íƒ€ë°ì´í„°ì™€ ëª¨ë¸ ìì²´ì˜ binary íŒŒì¼ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì´ `download_model()` ì´ë¼ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

```python
def download_model(args):
    # Download model artifacts
    mlflow.artifacts.download_artifacts(artifact_uri=f"runs:/{args.run_id}/{args.model_name}", dst_path=".")
```

MLFlow server ì—ì„œ `run_id` ì™€ `model_name` ì„ í™•ì¸í•˜ì—¬ ì…ë ¥í•´ì£¼ë©´ í•´ë‹¹í•˜ëŠ” ëª¨ë¸ì„ ì°¾ì•„ ë‹¤ìš´ë¡œë“œë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 1.4 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ë‹¤ìŒê³¼ ê°™ì´ `argparse` ë¥¼ ì´ìš©í•˜ì—¬ íŒŒë¼ë¯¸í„°ë¥¼ ì…ë ¥ë°›ì„ ìˆ˜ ìˆë„ë¡ í•˜ê³  `donwload_model()` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.

```python
if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument("--model-name", dest="model_name", type=str, default="sk_model")
    parser.add_argument("--run-id", dest="run_id", type=str)
    args = parser.parse_args()

    download_model(args)
```

### 1.5 `download_model.py`
ì‘ì„±í•œ ì½”ë“œë¥¼ ëª¨ìœ¼ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

```python title="download_model.py"
import os
from argparse import ArgumentParser

import mlflow

# Set environments
os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://localhost:9000"
os.environ["MLFLOW_TRACKING_URI"] = "http://localhost:5001"
os.environ["AWS_ACCESS_KEY_ID"] = "minio"
os.environ["AWS_SECRET_ACCESS_KEY"] = "miniostorage"


def download_model(args):
    # Download model artifacts
    mlflow.artifacts.download_artifacts(artifact_uri=f"runs:/{args.run_id}/{args.model_name}", dst_path=".")


if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument("--model-name", dest="model_name", type=str, default="sk_model")
    parser.add_argument("--run-id", dest="run_id", type=str)
    args = parser.parse_args()

    download_model(args)
```

### 1.6 ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
ë¨¼ì € ë‹¤ìš´ë¡œë“œë°›ê³ ì í•˜ëŠ” ëª¨ë¸ì˜ MLFlow ì„œë²„ì—ì„œ ì €ì¥ëœ `run_id` ì™€ `model_name` ì„ ì•Œì•„ì•¼ í•©ë‹ˆë‹¤.  
[http://localhost:5001](http://localhost:5001) ì— ì ‘ì†í•˜ì—¬ ëª¨ë¸ì´ ì €ì¥ëœ experiments ì™€ run ì„ ì„ íƒí•˜ì—¬ í´ë¦­í•©ë‹ˆë‹¤.
[ê·¸ë¦¼ 6-2]ì˜ ë¹¨ê°„ìƒ‰ ìƒì ë¶€ë¶„ì—ì„œ `run_id` ì™€ `model_name` ì„ ê°ê° í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<div style={{textAlign: 'center'}}>

![run detail](./img/api-serving-2.png)
[ê·¸ë¦¼ 6-2] Run Detail
</div>

ì´ì œ ì‘ì„±í•œ ìŠ¤í¬ë¦½íŠ¸ `download_model.py` ë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
```bash
# terminal-command
python download_model.py --model-name sk_model --run-id <run-id>
```
:::caution
`<run_id>` ë¶€ë¶„ì—ëŠ” MLFlow server ì— ì ‘ì†í•˜ì—¬ í™•ì¸í•œ ëª¨ë¸ì˜ `run_id` ë¥¼ ì…ë ¥í•´ì£¼ë©´ ë©ë‹ˆë‹¤.
:::

ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ë‚˜ë©´, `ch6` directory ì•ˆì— `sk_model` ì´ë¼ëŠ” directory ê°€ ìƒì„±ë©ë‹ˆë‹¤.

```bash
sk_model
â”œâ”€â”€ MLmodel
â”œâ”€â”€ conda.yaml
â”œâ”€â”€ input_example.json
â”œâ”€â”€ model.pkl
â”œâ”€â”€ python_env.yaml
â””â”€â”€ requirements.txt
```

`sk_model` ì•ˆì—ëŠ” ë‹¤ìš´ë¡œë“œë°›ì€ ëª¨ë¸ê³¼ ë©”íƒ€ë°ì´í„° ë“±ì´ ë“¤ì–´ ìˆìŠµë‹ˆë‹¤.
ëª¨ë¸ì´ ë“¤ì–´ìˆëŠ” ì´ directory ë¥¼ ì´ìš©í•´ ì´ì œ Model API ë¥¼ ì‘ì„±í•´ë³´ê² ìŠµë‹ˆë‹¤.

## 2. Model API ëª…ì„¸ì„œ ì‘ì„±
`POST /predict` ë¥¼ ìˆ˜í–‰í–ˆì„ ë•Œ í•™ìŠµí•œ ëª¨ë¸ì˜ inference ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì£¼ëŠ” API ì˜ ëª…ì„¸ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. Request body ë¡œ iris ë°ì´í„°ë¥¼ ì „ë‹¬í•´ì£¼ë©´ response body ë¥¼ í†µí•´ ì˜ˆì¸¡ëœ ê°’ì„ ì „ë‹¬ë°›ê²Œ ë©ë‹ˆë‹¤.  

ì´ë¥¼ í‘œë¡œ ë‚˜íƒ€ë‚´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

| Request Header | Request Body | Response Body |
| --- | --- | --- |
| POST /predict | {<br/>&emsp;"sepal_length": 6.7,&emsp;<br/>&emsp;"sepal_width": 3.3,<br/>&emsp;"petal_length": 5.7,<br/>&emsp;"petal_width": 2.1&emsp;<br/>} | {<br/>&emsp;"iris_class": 2&emsp;<br/>} |


## 3. Pydantic Model ë¡œ ìŠ¤í‚¤ë§ˆì˜ í´ë˜ìŠ¤ ì‘ì„±

### 3.1 Import
ë¨¼ì €, Pydantic Model ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ import í•©ë‹ˆë‹¤.

```python
from pydantic import BaseModel
```

### 3.2 Input schema
API ì—ì„œ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°€ê²Œ ë  ë°ì´í„°ì˜ ìŠ¤í‚¤ë§ˆë¥¼ í´ë˜ìŠ¤ë¡œ ì‘ì„±í•©ë‹ˆë‹¤. ìŠ¤í™ ëª…ì„¸ì„œì— ë§ê²Œ `Class PredictIn(BaseModel)` ì„ ì‘ì„±í•©ë‹ˆë‹¤.

```python
class PredictIn(BaseModel):
    sepal_length: float
    sepal_width: float
    petal_length: float
    petal_width: float
```

Iris ë°ì´í„°ì—ì„œ ê° column ì˜ ë°ì´í„° íƒ€ì…ì€ `float` ì´ë¯€ë¡œ ìœ„ì™€ ê°™ì´ ì‘ì„±í•´ ì¤ë‹ˆë‹¤.

### 3.3 Output schema

API ì—ì„œ ë°˜í™˜í•  ë°ì´í„°ì˜ ìŠ¤í‚¤ë§ˆë¥¼ í´ë˜ìŠ¤ë¡œ ì‘ì„±í•©ë‹ˆë‹¤. ìŠ¤í™ ëª…ì„¸ì„œì— ë§ê²Œ `Class PredictOut(BaseModel)` ì„ ì‘ì„±í•©ë‹ˆë‹¤.

```python
class PredictOut(BaseModel):
    iris_class: int
```

ëª¨ë¸ì´ ë°˜í™˜í•˜ëŠ” ê°’ì€ ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ë¡œ 0, 1, 2 ì¤‘ í•˜ë‚˜ì´ê¸° ë•Œë¬¸ì— `int` íƒ€ì…ìœ¼ë¡œ ì‘ì„±í•´ ì¤ë‹ˆë‹¤.

### 3.4 `schemas.py`
ì‘ì„±í•œ ì½”ë“œë¥¼ ëª¨ìœ¼ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

```python title="schemas.py"
from pydantic import BaseModel

class PredictIn(BaseModel):
    sepal_length: float
    sepal_width: float
    petal_length: float
    petal_width: float

class PredictOut(BaseModel):
    iris_class: int
```

## 4. Predict API êµ¬í˜„

### 4.1 Import

ë¨¼ì €, í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì„ import í•©ë‹ˆë‹¤.

```python
import mlflow
import pandas as pd
from fastapi import FastAPI
from schemas import PredictIn, PredictOut
```

### 4.2 Load model

ì•ì„œ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œë°›ì€ ëª¨ë¸ì„ load í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì´ `mlflow` íŒ¨í‚¤ì§€ë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ì„ ì‰½ê²Œ load í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
def get_model():
    model = mlflow.sklearn.load_model(model_uri="./sk_model")
    return model

MODEL = get_model()
```

### 4.3 Create a FastAPI instance

ì•ì„œ <Part>05. FastAPI</Part> íŒŒíŠ¸ì—ì„œ í•™ìŠµí•œ FastAPI ë¥¼ ì´ìš©í•´ API ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•´ FastAPI instance ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```python
# Create a FastAPI instance
app = FastAPI()
```

### 4.4 Write `predict` function

API ì— `POST /predict` ë¥¼ ìˆ˜í–‰í–ˆì„ ë•Œ í•™ìŠµí•œ ëª¨ë¸ì˜ inference ê²°ê³¼ë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆë„ë¡ `predict` í•¨ìˆ˜ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

```python
@app.post("/predict", response_model=PredictOut)
def predict(data: PredictIn) -> PredictOut:
    df = pd.DataFrame([data.dict()])
    pred = MODEL.predict(df).item()
    return PredictOut(iris_class=pred)
```

ìš”ì²­ë°›ì€ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ìˆœì„œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
1. `predict` í•¨ìˆ˜ëŠ” `PredictIn` í´ë˜ìŠ¤ì˜ ë°ì´í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³  `PredictOut` í´ë˜ìŠ¤ë¥¼ ë°˜í™˜í•˜ë„ë¡ í•©ë‹ˆë‹¤.
2. ì…ë ¥ë°›ì€ ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ í˜•íƒœë¡œ ë³€í™˜í•œ í›„, ìœ„ì—ì„œ ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ inference ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
3. ë§ˆì§€ë§‰ìœ¼ë¡œ ì €ì¥ëœ ê²°ê³¼ë¥¼ `PredictOut` í´ë˜ìŠ¤ì— ë„£ì–´ ë°˜í™˜í•˜ë©´ ë©ë‹ˆë‹¤.

`POST` method ë¥¼ ì´ìš©í•˜ì—¬ ì˜ˆì¸¡í•  ìˆ˜ ìˆë„ë¡ `@app.post` ë¥¼ ì´ìš©í•œ ë°ì½”ë ˆì´í„°ë¡œ í•¨ìˆ˜ë¥¼ ê°ì‹¸ì£¼ê³ , `response_model` ì€ `PredictOut` í´ë˜ìŠ¤ë¡œ ì§€ì •í•´ ì£¼ë©´ ë©ë‹ˆë‹¤.

### 4.5 `app.py`

ì‘ì„±í•œ ì½”ë“œë¥¼ ëª¨ìœ¼ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

```python title="app.py"
import mlflow
import pandas as pd
from fastapi import FastAPI
from schemas import PredictIn, PredictOut

def get_model():
    model = mlflow.sklearn.load_model(model_uri="./sk_model")
    return model

MODEL = get_model()

# Create a FastAPI instance
app = FastAPI()

@app.post("/predict", response_model=PredictOut)
def predict(data: PredictIn) -> PredictOut:
    df = pd.DataFrame([data.dict()])
    pred = MODEL.predict(df).item()
    return PredictOut(iris_class=pred)
```

## 5. API ì‘ë™ í™•ì¸
ì´ì œ ì‘ì„±í•œ API ì— ë°ì´í„°ë¥¼ ì „ë‹¬í•˜ì—¬ ì˜ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤.

ë¨¼ì € ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì—¬ ì‘ì„±í•œ API ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

```bash
# terminal-command
uvicorn app:app --reload
```

ì´ì œ [http://localhost:8000/docs](http://localhost:8000/docs) (FastAPI - Swagger UI) ì— ì ‘ì†í•˜ì—¬ ì‘ë™ í…ŒìŠ¤íŠ¸ë¥¼ í•´ ë´…ì‹œë‹¤.  
[ê·¸ë¦¼ 6-3]ê³¼ ê°™ì´ ì•ì„œ ì‘ì„±í•œ predict í•¨ìˆ˜ê°€ ë‚˜íƒ€ë‚˜ ìˆëŠ” í™”ë©´ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<div style={{textAlign: 'center'}}>

![model api server screen](./img/api-serving-3.png)
[ê·¸ë¦¼ 6-3] Model API Server Screen
</div>

API ë¥¼ ì‹¤í–‰í•˜ì—¬ ì•ì„œ ì‘ì„±í•œ ëª…ì„¸ì„œì— ë§ê²Œ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

<div style={{textAlign: 'center'}}>

![model api test screen](./img/api-serving-4.png)
[ê·¸ë¦¼ 6-4] Model API Test Screen
</div>

Request body ì˜ í˜•íƒœì— ì•Œë§ê²Œ ë°ì´í„°ë¥¼ ì „ë‹¬í•´ì£¼ë©´ [ê·¸ë¦¼ 6-4]ì˜ ë¹¨ê°„ìƒ‰ ë¶€ë¶„ê³¼ ê°™ì´ Response body ë¡œ inference ê²°ê³¼ê°€ ì˜ ë°˜í™˜ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
