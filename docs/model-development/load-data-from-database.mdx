---
sidebar_position: 3
description: ğŸ“Œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” íŒŒì´í”„ë¼ì¸ì„ ì‘ì„±í•©ë‹ˆë‹¤.
---

# 3) Load Data from Database
import CodeDescription from '@site/src/components/CodeDescription';
import BrowserWindow from '@site/src/components/BrowserWindow';


### ëª©í‘œ

1. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” íŒŒì´í”„ë¼ì¸ì„ ì‘ì„±í•©ë‹ˆë‹¤.

<details>
<summary>ìŠ¤í™ ëª…ì„¸ì„œ</summary>
<CodeDescription>

### ìŠ¤í™ ëª…ì„¸ì„œ

1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    - ì±•í„°2ì—ì„œ ìƒì„±í•œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    - `id` columnì„ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹  ë°ì´í„° 100ê°œë¥¼ ì¶”ì¶œí•˜ëŠ” ì¿¼ë¦¬ë¬¸ì„ ì‘ì„±í•©ë‹ˆë‹¤.
    - `pandas.read_sql` í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
2. ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ìˆ˜ì •
    - ì´ì „ ì¥ì—ì„œ ì‘ì„±í•œ íŒŒì´í”„ë¼ì¸ ì¤‘ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë¶€ë¶„ì„ ìœ„ì—ì„œ ì‘ì„±í•œ í•¨ìˆ˜ë¡œ ìˆ˜ì •í•©ë‹ˆë‹¤.
    - ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    - ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

</CodeDescription>
</details>

---

<BrowserWindow url="https://github.com/mlops-for-mle/mlops-for-mle/tree/main/ch2">

í•´ë‹¹ ì±•í„°ì˜ ì „ì²´ ì½”ë“œëŠ” [mlops-for-mle/ch2/](https://github.com/mlops-for-mle/mlops-for-mle/tree/main/ch2) ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```js
ch2
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ base_train.py
â”œâ”€â”€ base_validate_save_model.py
// highlight-next-line
â”œâ”€â”€ db_train.py
// highlight-next-line
â”œâ”€â”€ db_validate_save_model.py
â”œâ”€â”€ pipeline_train.py
â””â”€â”€ pipeline_validate_save_model.py
```

</BrowserWindow>


## 0.  íŒ¨í‚¤ì§€ ì„¤ì¹˜

ì´ë²ˆ ì¥ì—ì„œ ì‚¬ìš©í•  íŒ¨í‚¤ì§€ë“¤ì¸ `psycopg2-binary` ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```bash
# terminal-command
pip install psycopg2-binary
```

## 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

`id` columnì„ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹  ë°ì´í„° 100ê°œë¥¼ ì¶”ì¶œí•˜ëŠ” ì¿¼ë¦¬ë¬¸ì„ ì‘ì„±í•©ë‹ˆë‹¤.

```sql
SELECT * FROM iris_data ORDER BY id DESC LIMIT 100;
```

`psql` ì—ì„œ í•´ë‹¹ ì¿¼ë¦¬ë¬¸ì„ ì…ë ¥í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì¶œë ¥ë©ë‹ˆë‹¤.

```sql
mydatabase=# SELECT * FROM iris_data ORDER BY id DESC LIMIT 100;
  id  | sepal_length | sepal_width | petal_length | petal_width | target
------+--------------+-------------+--------------+-------------+--------
 3499 |          5.4 |         3.9 |          1.7 |         0.4 |      0
 3498 |          6.4 |         2.8 |          5.6 |         2.1 |      2
 3497 |          6.3 |         2.3 |          4.4 |         1.3 |      1
 3496 |          5.4 |         3.9 |          1.7 |         0.4 |      0
 3495 |          5.5 |         4.2 |          1.4 |         0.2 |      0
(...)
```

`pandas.read_sql` ëŠ” ì…ë ¥ argumentë¡œ Queryë¬¸ê³¼ DB Connectionì„ ë°›ìŠµë‹ˆë‹¤.

postgres ì— ì—°ê²°í•  ìˆ˜ ìˆëŠ” db connectionì„ ìƒì„± í›„ ì¿¼ë¦¬ë¬¸ê³¼ db ì»¤ë„¥ì…˜ì„ ì´ìš©í•´ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.

```python
import pandas as pd
import psycopg2

db_connect = psycopg2.connect(host="localhost", database="mydatabase", user="myuser", password="mypassword")
df = pd.read_sql("SELECT * FROM iris_data ORDER BY id DESC LIMIT 100", db_connect)
```

ì¶”ì¶œëœ ë°ì´í„°ë¥¼ í™•ì¸í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```python
print(df.head(5))
#      id  sepal_length  sepal_width  petal_length  petal_width  target
# 0  3499          5.4           3.9          1.7           0.4       0
# 1  3498          6.4           2.8          5.6           2.1       2
# 2  3497          6.3           2.3          4.4           1.3       1
# 3  3496          5.4           3.9          1.7           0.4       0
# 4  3495          5.5           4.2          1.4           0.2       0
```

## 2. ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ìˆ˜ì •

### 2.1 `db_train.py`

ìš°ì„  í•™ìŠµ ë° ë°ì´í„° ì €ì¥ì„ ìœ„í•œ ì½”ë“œë“¤ì„ ëª¨ì€ `base_train.py` ë¥¼ ìˆ˜ì •í•´ `db_train.py` ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

ë¨¼ì €  `# 1. get data` ë¶€ë¶„ì„ ìœ„ì—ì„œ ì‘ì„±í•œ ì½”ë“œë¡œ ìˆ˜ì •í•©ë‹ˆë‹¤.

ê·¸ë¦¬ê³  ì‚¬ìš©í•œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” `# 4. save data` ë¶€ë¶„ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ì´ìœ ëŠ” í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì— ê³„ì†í•´ì„œ ë°ì´í„°ê°€ ìŒ“ì´ê³  ìˆê¸° ë•Œë¬¸ì— ë§¤ë²ˆ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ë•Œë§ˆë‹¤ ë°ì´í„°ê°€ ë°”ë€ë‹ˆë‹¤.
ë°ì´í„°ê°€ ë°”ë€Œë©´ ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ì‚¬ìš©í•œ ë°ì´í„°ë¥¼ ì €ì¥í•´ í‰ê°€í•˜ëŠ” ë¶€ë¶„ì—ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python  title="db_train.py"
# db_train.py

import joblib
import pandas as pd
import psycopg2
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC

# 1. get data
db_connect = psycopg2.connect(host="localhost", database="mydatabase", user="myuser", password="mypassword")
df = pd.read_sql("SELECT * FROM iris_data ORDER BY id DESC LIMIT 100", db_connect)
X = df.drop(["id", "target"], axis="columns")
y = df["target"]
X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, random_state=2022)

# 2. model development and train
model_pipeline = Pipeline([("scaler", StandardScaler()), ("svc", SVC())])
model_pipeline.fit(X_train, y_train)

train_pred = model_pipeline.predict(X_train)
valid_pred = model_pipeline.predict(X_valid)

train_acc = accuracy_score(y_true=y_train, y_pred=train_pred)
valid_acc = accuracy_score(y_true=y_valid, y_pred=valid_pred)

print("Train Accuracy :", train_acc)
print("Valid Accuracy :", valid_acc)

# 3. save model
joblib.dump(model_pipeline, "db_pipeline.joblib")

# 4. save data
df.to_csv("data.csv", index=False)
```

### 2.2 `validate_save_model.py`

ë‹¤ìŒì€ ì €ì¥ëœ ëª¨ë¸ì„ ê²€ì¦í•˜ëŠ” `base_validate_save_model.py` ë¥¼ ìˆ˜ì •í•´ `db_validate_save_model.py` ë¡œ ì €ì¥í•©ë‹ˆë‹¤ ì…ë‹ˆë‹¤.
`# 1. reproduce data` ì—ì„œ ì €ì¥ëœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê²Œ ìˆ˜ì •í•©ë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ë¶€ë¶„ì€ ì´ ì „ ì¥ê³¼ ë™ì¼í•©ë‹ˆë‹¤.

```python  title="db_validate_save_model.py"
# db_validate_save_model.py

import joblib
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

# 1. reproduce data
df = pd.read_csv("data.csv")
X = df.drop(["id", "target"], axis="columns")
y = df["target"]
X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, random_state=2022)

# 2. load model
pipeline_load = joblib.load("db_pipeline.joblib")

# 3. validate
load_train_pred = pipeline_load.predict(X_train)
load_valid_pred = pipeline_load.predict(X_valid)

load_train_acc = accuracy_score(y_true=y_train, y_pred=load_train_pred)
load_valid_acc = accuracy_score(y_true=y_valid, y_pred=load_valid_pred)

print("Load Model Train Accuracy :", load_train_acc)
print("Load Model Valid Accuracy :", load_valid_acc)
```
